{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procedural program to get and analyze RSS-Newsfeeds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from requests_html import HTMLSession\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Show current working directory\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to get the content of RSS-Feeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_source(url):\n",
    "    \"\"\"\n",
    "    Provides source code of the website of the specified URL.\n",
    "\n",
    "    :param url: URL of the page to scrape. Type = str\n",
    "    :return: Response from serrver request. Type = requests_html.HTMLResponse\n",
    "    \"\"\"\n",
    "    try:\n",
    "        session = HTMLSession()\n",
    "        response = session.get(url)\n",
    "        return response\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(e)\n",
    "\n",
    "def get_single_feed(url):\n",
    "    \"\"\"\n",
    "    Derives the content of a single RSS-Feed for the provided URL.\n",
    "\n",
    "    :param url: URL of the page to scrape. Type = str\n",
    "    :return: HTTP response object from requests_html. Type = pandas.DataFrame\n",
    "    \"\"\"\n",
    "    response = get_source(url)\n",
    "    rows = []\n",
    "\n",
    "    with response as r:\n",
    "        items = r.html.find(\"item\", first=False)\n",
    "        for item in items:\n",
    "            title = item.find('title', first=True).text\n",
    "            pubDate = item.find('pubDate', first=True).text\n",
    "            guid = item.find('guid', first=True).text\n",
    "            description_element = item.find('description', first=True)\n",
    "            \n",
    "            # Check if 'description' element exists before accessing 'text'\n",
    "            description = description_element.text if description_element is not None else \"\"\n",
    "            \n",
    "            row = {'title': title, 'pubDate': pubDate, 'guid': guid, 'description': description}\n",
    "            rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    return df\n",
    "\n",
    "def get_multiple_feeds(url_list):\n",
    "    \"\"\"\n",
    "    Derives the content on RSS-Feed for the provided list of URLs.\n",
    "\n",
    "    :param url: URL of the page to scrape. Type = str\n",
    "    :return: HTTP response object from requests_html. Type = pandas.DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.DataFrame(columns = ['title', 'pubDate', 'guid', 'description'])\n",
    "\n",
    "    for url in url_list:\n",
    "\n",
    "        df_iter = get_single_feed(url)\n",
    "        df = pd.concat([df, df_iter], ignore_index=True)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting infos from single RSS-Feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call functions for single feed\n",
    "df_feed = get_single_feed('https://www.nzz.ch/international.rss')\n",
    "df_feed.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting infos from multiple RSS-Feeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List with RSS-Feeds (germ. and engl.)\n",
    "\n",
    "url_list = ['https://www.spiegel.de/schlagzeilen/index.rss',\n",
    "            'https://www.nzz.ch/international.rss',\n",
    "            'https://rss.nytimes.com/services/xml/rss/nyt/Europe.xml',\n",
    "            'https://rss.nytimes.com/services/xml/rss/nyt/World.xml']\n",
    "\n",
    "# Function call\n",
    "df_multi_feeds = get_multiple_feeds(url_list)\n",
    "df_multi_feeds.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the k most frequent words per RSS-Feed title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in df_multi_feeds['title']:\n",
    "\n",
    "    from collections import Counter\n",
    "    \n",
    "    split_txt = item.split()\n",
    "    Counter = Counter(split_txt)\n",
    "    most_occur = Counter.most_common(5)\n",
    "    print(most_occur)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a wordcloud with the most frequent words in RSS-Feed titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wordcloud function\n",
    "def wordCloud_generator(data, title=None):\n",
    "    \"\"\"\n",
    "    Creates a plot of a word cloud based on the given data\n",
    "\n",
    "    :param data: input data. Type = str\n",
    "    :param title: plot title. Type\n",
    "\n",
    "    \"\"\"\n",
    "    wordcloud = WordCloud(height=300,\n",
    "                          width=600,\n",
    "                          background_color ='black',\n",
    "                          min_font_size = 10\n",
    "                         ).generate(\" \".join(data.values))\n",
    "    \n",
    "    # Plot the WordCloud image                        \n",
    "    plt.figure(figsize = (6, 4), facecolor = None) \n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\") \n",
    "    plt.tight_layout(pad = 0) \n",
    "    plt.title(title,fontsize=16)\n",
    "    plt.show()\n",
    "    \n",
    "# Create Wordcloud\n",
    "wordCloud_generator(df_multi_feeds['title'], \n",
    "                    title=\"Most used words in RSS-Feed titles\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jupyter notebook --footer info-- (please always provide this at the end of each notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "import socket\n",
    "from platform import python_version\n",
    "from datetime import datetime\n",
    "\n",
    "print('-----------------------------------')\n",
    "print(os.name.upper())\n",
    "print(platform.system(), '|', platform.release())\n",
    "print('Datetime:', datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "print('Python Version:', python_version())\n",
    "print('-----------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
